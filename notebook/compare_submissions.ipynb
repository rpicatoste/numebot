{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreaload and show all outputs\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Show all outputs for each cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "round_number = 464\n",
    "global_folder = Path('/home/pica/hdd/nas/Data/numerai')\n",
    "data_folder =Path(f'/home/pica/nas_pica/Data/numerai/data/numerai_dataset_{round_number}')\n",
    "\n",
    "@dataclass\n",
    "class Version:\n",
    "    name: str\n",
    "    folder: Path\n",
    "    round_number: int\n",
    "\n",
    "poetry = Version(name='poetry', folder=global_folder / f'submissions', round_number=round_number)\n",
    "automl = Version(name='automl', folder=global_folder / f'submissions_bak_{round_number}_automl', round_number=round_number)\n",
    "versions = [poetry, automl]\n",
    "\n",
    "model_name = 'rpica_4'\n",
    "model_name = 'rpica'\n",
    "model_name = 'rpica_test_2'\n",
    "model_name = 'rpica_test_1'\n",
    "submission_relative = f'{model_name}/{model_name}_submission_{round_number}.csv'\n",
    "\n",
    "round_df = pd.read_csv(data_folder/'numerai_tournament_data.csv')\n",
    "\n",
    "round_df['data_type'].value_counts()\n",
    "is_live = round_df.set_index('id')['data_type'] == 'live'\n",
    "\n",
    "for version in versions:\n",
    "    path = version.folder / submission_relative\n",
    "    df = pd.read_csv(path).set_index('id')[is_live]\n",
    "    df['rank'] = df['prediction'].rank()\n",
    "    version.df = df\n",
    "    print(f'For {version.name}, shape: {version.df.shape}')\n",
    "\n",
    "df = pd.merge(poetry.df,\n",
    "              automl.df,\n",
    "              on='id',\n",
    "              suffixes=['_poetry', '_automl'])\n",
    "df['diff'] = poetry.df['prediction'] != automl.df['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con rpica_test_1 el rank es igual al 95.2%\n",
    "# Con rpica_test_2 el rank es igual al 100.0%\n",
    "# Con rpica_4 el rank es igual al 100.0%\n",
    "# Con rpica_1 el rank es igual al 100.0%\n",
    "\n",
    "rank_equal = df['rank_poetry'] == df['rank_automl']\n",
    "rank_equal.sum()/len(rank_equal)\n",
    "df[~rank_equal].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mirar lo de rows live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "folder = Path('/home/pica/nas_pica/Data/numerai/data/numerai_dataset_458')\n",
    "\n",
    "tournament_path = folder/'numerai_tournament_data.csv'\n",
    "train_path = folder/'numerai_training_data.csv'\n",
    "\n",
    "tournament_df = pd.read_csv(tournament_path)\n",
    "train_df = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in zip(['tournament', 'train'], [tournament_df, train_df]):\n",
    "    print(name)\n",
    "    print(df.shape)\n",
    "    feat_cols = [col for col in df.columns if col.startswith('feature')]\n",
    "    non_feat_cols = [col for col in df.columns if not col.startswith('feature')]\n",
    "    print(non_feat_cols)\n",
    "    print(df['data_type'].value_counts())\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tournament_df\n",
    "df['data_type'].value_counts()\n",
    "df['target'].value_counts(dropna=False)\n",
    "df['target'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numebot-thZm-WQi-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
